{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Question_Answering_BiDAF.ipynb","provenance":[{"file_id":"https://github.com/spark-ming/albert-qa-demo/blob/master/Question_Answering_with_ALBERT.ipynb","timestamp":1598458028761}],"private_outputs":true,"collapsed_sections":[],"toc_visible":true,"machine_shape":"hm"},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"1qfQAtRsMVl7"},"source":["# Question Answering with BiDAF and SQuAD (using AllenNLP)\n","\n","Author: Vladimir Araujo\n","\n","Based on: https://demo.allennlp.org/reading-comprehension"]},{"cell_type":"markdown","metadata":{"id":"cCUQZmkI1e_q"},"source":["## 1.0 Introduction\n","\n","Question Answering (QA) is a challenging task that NLP tries to solve. The aim is to provide solution to queries expressed in natural language automatically (Hovy, Gerber, Hermjakob, Junk, and Lin 2000). For instance, given the following context:\n","\n","> Santiago, also known as Santiago de Chile, is the capital and largest city of Chile as well as one of the largest cities in the Americas. It is the center of Chile's most densely populated region, the Santiago Metropolitan Region, whose total population is 7 million, of which more than 6 million live in the city's continuous urban area. The city is entirely located in the country's central valley. Most of the city lies between 500–650 m (1,640–2,133 ft) above mean sea level.\n","\n","We ask the question\n","\n","> How many people live in Santiago?\n","\n","We expect the QA system responds with something like this:\n","\n","> 7 million\n","\n","The BiDAF model was proposed by a team from the University of Washington in 2016. BiDAF handily beat the best QA models at that time and for several weeks topped the leaderboard of the Stanford Question and Answering Dataset (SQuAD), arguably the most well-known QA dataset. Although BiDAF’s performance has since been surpassed, the model remains influential in the QA domain. The technical innovation of BiDAF inspired the subsequent development of competing models such as ELMo and BERT, by which BiDAF was eventually dethroned.\n","\n","## BiDAF Architecture \n","\n","<figure>\n","<center>\n","<img src='https://allenai.github.io/bi-att-flow/BiDAF.png' width=\"700\" />\n","</center>\n","</figure>\n","\n","This model has 3 principal parts.\n","\n","1. **Embedding Layers:**\n","BiDAF has 3 embedding layers whose function is to change the representation of words in the Query and the Context from strings into vectors of numbers.\n","2. **Attention and Modeling Layers:**\n","These Query and Context representations then enter the attention and modeling layers. These layers use several matrix operations to fuse the information contained in the Query and the Context. The output of these steps is another representation of the Context that contains information from the Query. This output is referred to in the paper as the “Query-aware Context representation.”\n","3. **Output Layer:**\n","The Query-aware Context representation is then passed into the output layer, which will transform it to a bunch of probability values. These probability values will be used to determine where the Answer starts and ends."]},{"cell_type":"markdown","metadata":{"id":"sBBHbGvQN5vX"},"source":["## 2.0 Setup\n","\n","First, we install AllenNLP with pip.\n","\n","Note: run the commented line only in case the following error appears. `The NVIDIA driver on your system is too old (found version 10010)`"]},{"cell_type":"code","metadata":{"id":"TRZned-8WJrj"},"source":["# pip install torch==1.5.0+cu101 torchvision==0.6.0+cu101 -f https://download.pytorch.org/whl/torch_stable.html\n","!pip install allennlp allennlp-models"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"UHCuzhPptH0M"},"source":["## 3.0 Train Model\n","\n","This is where we can train our own model."]},{"cell_type":"markdown","metadata":{"id":"lsX38zc1kRZJ"},"source":["### 3.1 Get Training and Evaluation Data\n","\n","The [SQuAD](https://rajpurkar.github.io/SQuAD-explorer/) is a reading comprehension dataset, consisting of questions posed by crowdworkers on a set of Wikipedia articles, where the answer to every question is a segment of text, or span, from the corresponding reading passage, or the question might be unanswerable. Read more about this dataset here: https://rajpurkar.github.io/SQuAD-explorer/\n","\n","Now get the SQuAD V1.1 dataset. `squad-train-v1.1.json` is for training and `squad-dev-v1.1.json` is for evaluation to see how well your model trained."]},{"cell_type":"code","metadata":{"id":"dI6e-PfOXSnO"},"source":["!wget https://allennlp.s3.amazonaws.com/datasets/squad/squad-train-v1.1.json \\\n","&& wget https://allennlp.s3.amazonaws.com/datasets/squad/squad-dev-v1.1.json"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"OaQGsAiWXcnd"},"source":["### 3.2 Configuration file for training\n","\n","AllenNLP uses configuration files for ease of use. This is a Jsonnet file that defines all the parameters for our experiment and model. Don't worry if you're not familiar with Jsonnet, any JSON file is valid Jsonnet.\n","\n","First, we download the config file of BiDAF created by AllenNLP."]},{"cell_type":"code","metadata":{"id":"nVZXTYqbxbsp"},"source":["!pip install jsonnet\n","!wget https://raw.githubusercontent.com/allenai/allennlp-models/v1.0.0/training_config/rc/bidaf_elmo.jsonnet"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"5-p_VOrfD5RP"},"source":["Now, we can load the JSON file and explore it.\n","\n","**Notes about hyper-parameters:**\n","\n","The file containts the original configurations of BiDAF and is ready to use. However, we could edit any value if we want. Among the most important parameters are:\n","\n","`train_data_path` and `validation_data_path` specifies the path or url of the dataset\n","\n","`num_epochs` specifies the number to be trained\n","\n","`batch_size` specifies the size of the batch for training\n","\n","`cuda_device` set to `0` indicates that GPU will be used"]},{"cell_type":"code","metadata":{"id":"4CF-Dyu_xjtI"},"source":["import json\n","import _jsonnet\n","\n","jsonnet_file = \"bidaf_elmo.jsonnet\"\n","config_file = json.loads(_jsonnet.evaluate_file(jsonnet_file))\n","config_file"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"dZ87q93GDeeL"},"source":["### 3.3 Run training (Optional)\n","\n","We can now train the model with the training set.\n","\n","NOTE: it takes about 30 minutes to train an epoch (we run 20 epochs)! If you don't want to wait this long, feel free to skip this step and note the comment in the code to use a pretrained model!\n","\n","### Mandatory parameters:\n","`-s` specifies the output folder where the trained model will be stored.\n","\n","### Optional parameters:\n","\n","`-o` `overrides` function allows to rewrite a parameter of a config file. \n","\n","For instance, `-o '{\"validation_data_path\": \"alternative_dataset.json\"}'`\n","\n","In this case, we will run the training with default config file"]},{"cell_type":"code","metadata":{"id":"-Eg53t3QXZAb"},"source":["!allennlp train bidaf_elmo.jsonnet \\\n","  -s /content/model_output \\\n","  -o '{\"train_data_path\": \"squad-train-v1.1.json\" , \"validation_data_path\": \"squad-dev-v1.1.json\"}'"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"-JCNRkQwUD56"},"source":["## 4.0 Setup prediction code\n","\n","Now we can use the AlenNLP library to make predictions using a pre-trained model on SQuAD v1.1.\n","\n","NOTE if you decided train your own model, change the `model_path`\n"]},{"cell_type":"code","metadata":{"id":"cGBMqw_ZJa5Z"},"source":["!wget https://storage.googleapis.com/allennlp-public-models/bidaf-elmo-model-2020.03.19.tar.gz"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"2TEtCZXpJe__"},"source":["from allennlp.predictors.predictor import Predictor\n","import allennlp_models.rc\n","\n","model_path = \"bidaf-elmo-model-2020.03.19.tar.gz\"\n","predictor = Predictor.from_path(model_path)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"nIQOB8vhpcKs"},"source":["## 5.0 Run predictions\n","\n","Now for the fun part... testing out your model on different inputs. Pretty rudimentary example here. But the possibilities are endless with this function."]},{"cell_type":"code","metadata":{"id":"pw4kv4cZJjN4"},"source":["context = \"Santiago, also known as Santiago de Chile, is the capital and largest city of Chile as well as one of the largest cities in the Americas. It is the center of Chile's most densely populated region, the Santiago Metropolitan Region, whose total population is 7 million, of which more than 6 million live in the city's continuous urban area. The city is entirely located in the country's central valley. Most of the city lies between 500–650 m (1,640–2,133 ft) above mean sea level.\"\n","\n","question = \"What is the capital of Chile?\"\n","# question = \"How many people live in Santiago?\"\n","\n","# run prediction\n","answer = predictor.predict_json({\n","  \"passage\": context,\n","  \"question\": question\n","})\n","\n","# Print results\n","print(\"Results:\")\n","print(question,answer['best_span_str'])"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"rkivu8FOqp_8"},"source":["## 6.0 Activity\n","\n","Now is your turn. Use the code in Section 4.0 (previous section) to generate your own predictions. To do that, you must change the context variables and questions.\n"]},{"cell_type":"code","metadata":{"id":"dmf_DUvufzRc"},"source":["# Your code here"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"8hiZQy8K02ul"},"source":["---\n","\n","Based on this tutorial and the class, set whether the following statements are `True` or `False`.\n"]},{"cell_type":"code","metadata":{"id":"VOfTYECTrBi2","cellView":"form"},"source":["#@title The SQuAD dataset is a reading comprehension task\n","answer = None #@param [\"None\",\"False\", \"True\"] {type:\"raw\"}"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"cellView":"form","id":"NmaHQoIxsfPj"},"source":["#@title The BiDAF model is an ELMo model fine-tuned\n","answer = None #@param [\"None\",\"False\", \"True\"] {type:\"raw\"}"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"cellView":"form","id":"qswjW9-dsfcV"},"source":["#@title The BiDAF model consists of a single LSTM model\n","answer = None #@param [\"None\",\"False\", \"True\"] {type:\"raw\"}"],"execution_count":null,"outputs":[]}]}