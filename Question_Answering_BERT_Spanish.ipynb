{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Question_Answering_BERT_Spanish.ipynb","provenance":[{"file_id":"https://github.com/spark-ming/albert-qa-demo/blob/master/Question_Answering_with_ALBERT.ipynb","timestamp":1598458028761}],"private_outputs":true,"collapsed_sections":[],"toc_visible":true,"machine_shape":"hm"},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"liUyrLrddueP"},"source":["# Question Answering with BERT and SQuAD Spanish (using Hugging Face)\n","\n","Author: Vladimir Araujo\n","\n","Based on: https://www.spark64.com/post/machine-comprehension\n","\n"]},{"cell_type":"markdown","metadata":{"id":"1qfQAtRsMVl7"},"source":["## 1.0 Introduction\n","\n","Question Answering (QA) is a challenging task that NLP tries to solve. The aim is to provide solution to queries expressed in natural language automatically (Hovy, Gerber, Hermjakob, Junk, and Lin 2000). For instance, given the following context:\n","\n","> Quito, oficialmente San Francisco de Quito, es la capital de la República del Ecuador, de la Provincia de Pichincha y la capital más antigua de Sudamérica. Es la ciudad más poblada del Ecuador,​ con 2 millones de habitantes en el área urbana, y aproximadamente 3 millones en todo el Área metropolitana.\n","\n","We ask the question\n","\n","> ¿Cuál es la población de Quito?\n","\n","We expect the QA system responds with something like this:\n","\n","> 2 millones\n","\n","Since 2017, transformer models have been shown to outperform existing approaches for this task. Currently, many pretrained transformer models exist, including BERT, GPT-2, XLNet.\n","\n","This tutorial shows how you can fine-tune BERT for the task of QA and use it for inference. We will use the transformer library built by [Hugging Face](https://huggingface.co/), which is an extremely useful implementation of the transformer models in both TensorFlow and PyTorch. You can just use a fine-tuned model from their [model hub](https://huggingface.co/models). \n"," \n","This tutorial is for educational purposes with which we will learn to finetune a BERT model and use it with your own data.\n","\n","## Using BERT-based model for QA\n","\n","<figure>\n","<center>\n","<img src='https://miro.medium.com/max/1840/1*QhIXsDBEnANLXMA0yONxxA.png' width=\"500\" />\n","</center>\n","</figure>\n","\n","*   Input is the $Question$ tokens and the $Paragraph$ tokens separated by the special token $[SEP]$. \n","*   The final hidden vector of BERT is $T_i$\n","*   New parameters learned during fine-tuning are a start vector $S$ and an end vector $E$.\n","*   The probability of word $i$ being the start/end of the answer span is computed as a dot product between $T_{i}$ and $S$ or $E$ followed by a softmax."]},{"cell_type":"markdown","metadata":{"id":"sBBHbGvQN5vX"},"source":["## 2.0 Setup\n","\n","First, we clone and install the Hugging Face transformer library from Github."]},{"cell_type":"code","metadata":{"id":"QOAoUwBFMQCg"},"source":["!git clone https://github.com/huggingface/transformers \\\n","&& cd transformers \\\n","&& git checkout a3085020ed0d81d4903c50967687192e3101e770 "],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"TRZned-8WJrj"},"source":["!pip install ./transformers"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"UHCuzhPptH0M"},"source":["## 3.0 Train Model\n","\n","This is where we can train our own model."]},{"cell_type":"markdown","metadata":{"id":"OaQGsAiWXcnd"},"source":["### 3.1 Get Training and Evaluation Data\n","\n","The [SQuAD](https://rajpurkar.github.io/SQuAD-explorer/) is a reading comprehension dataset, consisting of questions posed by crowdworkers on a set of Wikipedia articles, where the answer to every question is a segment of text, or span, from the corresponding reading passage, or the question might be unanswerable. In this tutorial we will use a Spanish version of this dataset. \n","\n","Read more about this dataset here: https://github.com/ccasimiro88/TranslateAlignRetrieve\n","\n","Now get the SQuAD V2.0 dataset. `train-v2.0-es_small.json\n","` is for training and `dev-v2.0-es_small.json` is for evaluation to see how well your model trained. Note that we use the small version for convenience.\n","\n"]},{"cell_type":"code","metadata":{"id":"4Qivanca5hdf"},"source":["!mkdir dataset \\\n","&& cd dataset \\\n","&& wget https://github.com/ccasimiro88/TranslateAlignRetrieve/raw/master/SQuAD-es-v2.0/train-v2.0-es_small.json \\\n","&& wget https://github.com/ccasimiro88/TranslateAlignRetrieve/raw/master/SQuAD-es-v2.0/dev-v2.0-es_small.json"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"qHfFa_NCXlOg"},"source":["### 3.2 Dataset Exploration\n","\n","Let's explore an example of the dataset. We define a function for loading the json file of the SQuAD dataset."]},{"cell_type":"code","metadata":{"id":"byYER0g2a6E7"},"source":["!wget https://gist.githubusercontent.com/vgaraujov/fd17b0c151657fbce73189a98617f1c6/raw/f677ae68aaa9cb6dc274cdbf44e60b12653c6cea/squad_utils.py"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"w9r0gH5yYNS-"},"source":["Now we can load the a split of the dataset and see an instance. You need to change `id` variable if you want to change the example."]},{"cell_type":"code","metadata":{"id":"7V_Wr1iablha"},"source":["import squad_utils\n","\n","dev_data = squad_utils.json_to_dataframe('dataset/dev-v2.0-es_small.json')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"vDijhQX8WSAC"},"source":["id = 100"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"CHoPfUqWSNm8"},"source":["dev_data.iloc[id]['context']"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"vKzF4bgqWAnB"},"source":["dev_data.iloc[id]['question']"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"YSMTuv1FWDFO"},"source":["dev_data.iloc[id]['text']"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"ffspWaICW9yT"},"source":["dev_data.iloc[id]['ans_start']"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"dZ87q93GDeeL"},"source":["### 3.3 Run training (Optional)\n","\n","We can now train the model with the training set. \n","\n","**Notes about parameters:**\n","\n","`per_gpu_train_batch_size` specifies the number of training examples per iteration per GPU.\n","\n","`save_steps` specifies number of steps before it outputs a checkpoint file. I've increased it to save disk space.\n","\n","`num_train_epochs` sets the number of epochs, two epochs are recommended. It's currently set to one for the purpose of time.\n","\n","`version_2_with_negative` is required for SQuAD V2.0. If training with V1.1, take out this flag.\n","\n","NOTE: it takes about 1 hour to train an epoch! If you don't want to wait this long, feel free to skip this step and use a pretrained model!"]},{"cell_type":"code","metadata":{"id":"Z75F_lxhIk6m"},"source":["!export SQUAD_DIR=/content/dataset \\\n","&& python transformers/examples/run_squad.py \\\n","  --model_type bert \\\n","  --model_name_or_path dccuchile/bert-base-spanish-wwm-cased \\\n","  --do_train \\\n","  --do_eval \\\n","  --do_lower_case \\\n","  --train_file $SQUAD_DIR/train-v2.0-es_small.json \\\n","  --predict_file $SQUAD_DIR/dev-v2.0-es_small.json \\\n","  --per_gpu_train_batch_size 12 \\\n","  --learning_rate 3e-5 \\\n","  --num_train_epochs 2.0 \\\n","  --max_seq_length 384 \\\n","  --doc_stride 128 \\\n","  --output_dir /content/model_output \\\n","  --save_steps 5000 \\\n","  --threads 4 \\\n","  --version_2_with_negative "],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"-JCNRkQwUD56"},"source":["## 4.0 Setup prediction code\n","\n","Now we can use the Hugging Face library to make predictions using our model. Note that a lot of the code is pulled from `run_squad.py` in the Hugging Face repository, with all the training parts removed.\n"]},{"cell_type":"code","metadata":{"id":"1pbwVAf3nmlO"},"source":["import os\n","import torch\n","import time\n","from torch.utils.data import DataLoader, RandomSampler, SequentialSampler\n","\n","from transformers import (\n","    AutoTokenizer, \n","    AutoModelForQuestionAnswering,\n","    squad_convert_examples_to_features\n",")\n","\n","from transformers.data.processors.squad import SquadResult, SquadV2Processor, SquadExample\n","from transformers.data.metrics.squad_metrics import compute_predictions_logits"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Op9OKbPCo-2C"},"source":["If you have trained your own mode, you need to change the flag `use_own_model` to `True`. However, in the case that you want to use a pre-trained model of the hub, you need to change the flag `use_own_model` to `False`, and define the model variable `model_name_or_path`.\n","\n","In this tutorial, we will use a pre-trained model on SQuAD spanish called [`mrm8488/distill-bert-base-spanish-wwm-cased-finetuned-spa-squad2-es`](https://huggingface.co/mrm8488/distill-bert-base-spanish-wwm-cased-finetuned-spa-squad2-es)."]},{"cell_type":"code","metadata":{"id":"29WwhgAmnp-n"},"source":["# READER NOTE: Set this flag to use own model, or use pretrained model in the Hugging Face repository\n","use_own_model = False\n","\n","if use_own_model:\n","  model_name_or_path = \"/content/model_output\"\n","else:\n","  model_name_or_path = \"mrm8488/distill-bert-base-spanish-wwm-cased-finetuned-spa-squad2-es\"\n","\n","output_dir = \"\"\n","\n","# Config\n","n_best_size = 1\n","max_answer_length = 30\n","do_lower_case = True\n","null_score_diff_threshold = 0.0\n","\n","def to_list(tensor):\n","    return tensor.detach().cpu().tolist()\n","\n","# Setup model\n","model_class, tokenizer_class = (AutoModelForQuestionAnswering, AutoTokenizer)\n","tokenizer = tokenizer_class.from_pretrained(\n","    model_name_or_path, do_lower_case=True)\n","model = model_class.from_pretrained(model_name_or_path)\n","\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","\n","model.to(device)\n","\n","processor = SquadV2Processor()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"bC0FP6APt03a"},"source":["Esta es una función prestada de `run_squad.py`.  This modified code allows to run predictions we pass in directly as strings, rather .json format like the training/test set."]},{"cell_type":"code","metadata":{"cellView":"code","id":"9jZkAMli9tot"},"source":["def run_prediction(question_texts, context_text):\n","    \"\"\"Setup function to compute predictions\"\"\"\n","    examples = []\n","\n","    for i, question_text in enumerate(question_texts):\n","        example = SquadExample(\n","            qas_id=str(i),\n","            question_text=question_text,\n","            context_text=context_text,\n","            answer_text=None,\n","            start_position_character=None,\n","            title=\"Predict\",\n","            is_impossible=False,\n","            answers=None,\n","        )\n","\n","        examples.append(example)\n","\n","    features, dataset = squad_convert_examples_to_features(\n","        examples=examples,\n","        tokenizer=tokenizer,\n","        max_seq_length=384,\n","        doc_stride=128,\n","        max_query_length=64,\n","        is_training=False,\n","        return_dataset=\"pt\",\n","        threads=1,\n","    )\n","\n","    eval_sampler = SequentialSampler(dataset)\n","    eval_dataloader = DataLoader(dataset, sampler=eval_sampler, batch_size=10)\n","\n","    all_results = []\n","\n","    for batch in eval_dataloader:\n","        model.eval()\n","        batch = tuple(t.to(device) for t in batch)\n","\n","        with torch.no_grad():\n","            inputs = {\n","                \"input_ids\": batch[0],\n","                \"attention_mask\": batch[1],\n","                \"token_type_ids\": batch[2],\n","            }\n","\n","            example_indices = batch[3]\n","\n","            outputs = model(**inputs)\n","\n","            for i, example_index in enumerate(example_indices):\n","                eval_feature = features[example_index.item()]\n","                unique_id = int(eval_feature.unique_id)\n","\n","                output = [to_list(output[i]) for output in outputs]\n","\n","                start_logits, end_logits = output\n","                result = SquadResult(unique_id, start_logits, end_logits)\n","                all_results.append(result)\n","\n","    output_prediction_file = \"predictions.json\"\n","    output_nbest_file = \"nbest_predictions.json\"\n","    output_null_log_odds_file = \"null_predictions.json\"\n","\n","    predictions = compute_predictions_logits(\n","        examples,\n","        features,\n","        all_results,\n","        n_best_size,\n","        max_answer_length,\n","        do_lower_case,\n","        output_prediction_file,\n","        output_nbest_file,\n","        output_null_log_odds_file,\n","        False,  # verbose_logging\n","        True,  # version_2_with_negative\n","        null_score_diff_threshold,\n","        tokenizer,\n","    )\n","\n","    return predictions"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"nIQOB8vhpcKs"},"source":["## 5.0 Run predictions\n","\n","Now for the fun part... testing out your model on different inputs. Pretty rudimentary example here. But the possibilities are endless with this function."]},{"cell_type":"code","metadata":{"id":"F-sUrcA5nXTH","cellView":"code"},"source":["context = \"Quito, oficialmente San Francisco de Quito, es la capital de la República del Ecuador, de la Provincia de Pichincha y la capital más antigua de Sudamérica. Es la ciudad más poblada del Ecuador,​ con 2 millones de habitantes en el área urbana, y aproximadamente 3 millones en todo el Área metropolitana.\"\n","questions = [\"¿Cuál es la población de Quito?\", \n","             \"¿En qué provincia esta ubicado Quito?\"]\n","\n","# Run method\n","predictions = run_prediction(questions, context)\n","\n","# Print results\n","print(\"Results:\")\n","for i, key in enumerate(predictions.keys()):\n","  print(questions[i],predictions[key])"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"rkivu8FOqp_8"},"source":["## 6.0 Activity"]},{"cell_type":"markdown","metadata":{"id":"7-YpxGCFvZlR"},"source":["Now is your turn. Use the code in Section 4.0 (previous section) to generate your own predictions. To do that, you must change the context variables and questions."]},{"cell_type":"code","metadata":{"id":"dmf_DUvufzRc"},"source":["# Your code here"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"C7x2k-5DPofz"},"source":["---\n","\n","Based on this tutorial and the class, set whether the following statements are `True` or `False`.\n"]},{"cell_type":"code","metadata":{"id":"VOfTYECTrBi2","cellView":"form"},"source":["#@title The SQuAD dataset is a reading comprehension task\n","answer = None #@param [\"None\",\"False\", \"True\"] {type:\"raw\"}"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"cellView":"form","id":"NmaHQoIxsfPj"},"source":["#@title The BERT model is trained from scratch for the QA task\n","answer = None #@param [\"None\",\"False\", \"True\"] {type:\"raw\"}"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"cellView":"form","id":"qswjW9-dsfcV"},"source":["#@title This model generates the response word by word (generative approach)\n","answer = None #@param [\"None\",\"False\", \"True\"] {type:\"raw\"}"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"P1mjfUNT_2Kc"},"source":["## 6.0 Bonus: Attention Vizualization\n","\n","The attention heads of the Transformer capture the relationships between the tokens. We can explore them to understand which tokens contribute the most to the prediction.\n","\n","*BertViz* is a tool for visualizing attention in the Transformer model, supporting all models from the HuggingFace library. First, we clone and install the library from Github."]},{"cell_type":"code","metadata":{"id":"OkotcgDs_4e7"},"source":["import sys\n","!test -d bertviz_repo && echo \"FYI: bertviz_repo directory already exists, to pull latest version uncomment this line: !rm -r bertviz_repo\"\n","# !rm -r bertviz_repo # Uncomment if you need a clean pull from repo\n","!test -d bertviz_repo || git clone https://github.com/jessevig/bertviz bertviz_repo\n","if not 'bertviz_repo' in sys.path:\n","  sys.path += ['bertviz_repo']\n","!pip install regex"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"_gDFy65bKzfO"},"source":["def call_html():\n","  import IPython\n","  display(IPython.core.display.HTML('''\n","        <script src=\"/static/components/requirejs/require.js\"></script>\n","        <script>\n","          requirejs.config({\n","            paths: {\n","              base: '/static/base',\n","              \"d3\": \"https://cdnjs.cloudflare.com/ajax/libs/d3/3.5.8/d3.min\",\n","              jquery: '//ajax.googleapis.com/ajax/libs/jquery/2.0.0/jquery.min',\n","            },\n","          });\n","        </script>\n","        '''))"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"TlDbLLexVF4S"},"source":["Now it is necessary to load the pre-trained model on SQuAD."]},{"cell_type":"code","metadata":{"id":"9aTtsBW1KwiF"},"source":["from bertviz import head_view\n","from transformers import BertTokenizer, BertModel"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"ekGDOWAsK4mk"},"source":["do_lower_case = True\n","model = BertModel.from_pretrained(model_name_or_path, output_attentions=True)\n","tokenizer = BertTokenizer.from_pretrained(model_name_or_path, do_lower_case=do_lower_case)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"eDFTmKzuVcfD"},"source":["In order to visualize the attentions we need to define `sentence_a` and \n","`sentence_b`. Remember that the input for BERT QA is `[question,context]`.\n","\n","Note: You need to set correctly `sentence_b_start` parameter in the `head_view` function depending on the length of your question."]},{"cell_type":"code","metadata":{"id":"_Q9WzzxhK9Hq"},"source":["sentence_b = \"Quito, oficialmente San Francisco de Quito, es la capital de la República del Ecuador, de la Provincia de Pichincha y la capital más antigua de Sudamérica.\"\n","sentence_a = \"¿En qué provincia esta ubicado Quito?\"\n","\n","inputs = tokenizer.encode_plus(sentence_a, sentence_b, return_tensors='pt', add_special_tokens=True)\n","token_type_ids = inputs['token_type_ids']\n","input_ids = inputs['input_ids']\n","attention = model(input_ids, token_type_ids=token_type_ids)[-1]\n","input_id_list = input_ids[0].tolist() # Batch index 0\n","tokens = tokenizer.convert_ids_to_tokens(input_id_list)\n","call_html()\n","\n","head_view(attention, tokens, sentence_b_start = 10)"],"execution_count":null,"outputs":[]}]}